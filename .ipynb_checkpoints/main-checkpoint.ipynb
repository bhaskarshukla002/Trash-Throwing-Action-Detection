{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea56f3d3-314e-49d6-a2db-007c74de8ea4",
   "metadata": {},
   "source": [
    "### Install necessary packages\n",
    "<br>!pip install opencv-python-headless\n",
    "<br>!pip install numpy\n",
    "<br>!pip install torch\n",
    "<br>!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f8be6-c8a7-41db-b0e3-52cb6430e239",
   "metadata": {},
   "source": [
    "# Results example\n",
    "<video controls  src=\"resultdemo.mp4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c74162-696a-46a6-aeef-714136a59421",
   "metadata": {},
   "source": [
    "## Imports \n",
    "project requires several key libraries to perform specific tasks related to video processing, object detection, and tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9072e4d-3fe3-4bc4-a909-6d51aec1cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51f573-2d51-4413-90ee-9819fa088515",
   "metadata": {},
   "source": [
    "### set the cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf836b9-d739-4fbd-a83f-e7fb080c6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057d794-601e-4bd9-b327-214f222b09e7",
   "metadata": {},
   "source": [
    "### check if device is cuda or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51218af1-a599-4461-a846-5a50d044df2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc831f-3a45-468e-9e63-d49970f0b31f",
   "metadata": {},
   "source": [
    "### initalize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3833caac-e268-4491-8f69-97002f0676e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-pose.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82456598-12ff-49d7-b11a-457b44958e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_bbox = None\n",
    "current_hand = None  \n",
    "tracker = cv2.TrackerKCF_create()\n",
    "tracker_initialized = False\n",
    "thrown=False\n",
    "kernel=None\n",
    "selected_pt=None\n",
    "selected_hand=None\n",
    "selected_pt_1=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ac8ec-f175-4704-a611-fbfba48a6347",
   "metadata": {},
   "source": [
    "This function initializes video capture from a specified file and attempts to set the frame width and height to 1280x720. It verifies if these settings were applied, printing a warning if they were not. Finally, it returns the video capture object for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bd8233-bd0c-4783-8443-7d226c0da43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_video(video_path, width=1280, height=720):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return None\n",
    "    \n",
    "    # Try setting the desired frame width and height\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "    # Verify if the settings were applied\n",
    "    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    if actual_width != width or actual_height != height:\n",
    "        print(f\"Warning: Desired dimensions ({width}x{height}) not applied. Actual dimensions: {actual_width}x{actual_height}\")\n",
    "\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896e459-8d32-4992-96fa-20ac1a0d6f81",
   "metadata": {},
   "source": [
    "This function checks if any point in a given contour is within a specified distance (threshold) from a keypoint. It calculates the Euclidean distance between each contour point and the keypoint. If any distance is less than the threshold, it returns True; otherwise, it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37106e6-649f-4cb4-8ddb-1920b4d95793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contour_connected_to_keypoint(contour, keypoint, threshold=10):\n",
    "    for point in contour:\n",
    "        distance = np.linalg.norm(point[0] - keypoint)\n",
    "        if distance < threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2afd28-51fe-462c-9b13-6dc87dd203c9",
   "metadata": {},
   "source": [
    "This function determines if an object, represented by its bounding box, is far enough from a given keypoint to be considered a \"throwing action.\" It calculates the distance between the object's center and the keypoint. If this distance is greater than or equal to the specified threshold, it returns True; otherwise, it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f45135-74a0-47f2-b4b2-66d62898c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_throwing_action(bbox, keypoint,threshold=50):\n",
    "    x_contour, y_contour, width, height = bbox\n",
    "    obj_center = np.array([x_contour + width / 2, y_contour + height / 2])\n",
    "    if(keypoint[0]!=0 and keypoint[1]!=0):\n",
    "        distance = np.linalg.norm(obj_center - keypoint)\n",
    "        print(f\"Distance to keypoint  [{keypoint}] : {distance:.2f}\")\n",
    "        if distance>=threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a12bc4-d276-4caf-b69e-1a451d8f2530",
   "metadata": {},
   "source": [
    "This function converts the input frame to grayscale and calculates the absolute difference with a background frame. Then, it applies Otsu's thresholding to create a binary mask, followed by erosion and dilation to reduce noise and enhance the foreground mask, which it then returns.\n",
    "\n",
    "<img src=\"result images/frame_3.jpg\" width=\"400\" height=\"200\"><img src=\"result images/frame_0.jpg\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b890cdcf-f0dd-42ce-a2ee-aa4ac5789e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_foreground(frame):\n",
    "    fgframe = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    fgMask = cv2.absdiff(fgframe, backframe)\n",
    "    _, fgMask = cv2.threshold(fgMask, 0, 255, cv2.THRESH_OTSU)\n",
    "    fgMask = cv2.erode(fgMask, kernel, iterations=1)\n",
    "    fgMask = cv2.dilate(fgMask, kernel, iterations=1)\n",
    "    return fgMask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce51ae-7f29-4238-ac82-0b53f58a3a83",
   "metadata": {},
   "source": [
    "This function processes a video frame with a YOLO model to track human poses. It extracts bounding boxes, keypoints, and IDs of detected individuals, and then returns these detections.\n",
    "<img src=\"result images/frame_3.jpg\" width=\"400\" height=\"200\"><img src=\"result images/frame_1.jpg\" width=\"400\" height=\"200\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60907567-571e-4898-b23d-0d91ccced413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_human_pose(frame):\n",
    "    results = model.track(frame, persist=True, tracker='bytetrack.yaml')\n",
    "    boundingboxes = results[0].boxes.xywh.cpu().numpy()\n",
    "    keypoints_list = results[0].keypoints.xy.cpu().numpy()\n",
    "    ids = {}\n",
    "    if results[0].boxes.id is not None:\n",
    "        ids = results[0].boxes.id.cpu().numpy()  # Extract track IDs\n",
    "    return boundingboxes, keypoints_list, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f9a39-6336-42bc-8401-9c01f662fb86",
   "metadata": {},
   "source": [
    "This Python function, draw_contours, takes a frame and a list of contour information. It sorts the contours based on their area, selects the largest one, and draws a rectangle around it on the frame. Additionally, it annotates the contour with a text indicating its ID, type of hand, and that it's an object. Finally, it returns the hand type, the point selected, and the coordinates of the rectangle enclosing the contour.\n",
    "\n",
    "\n",
    "<img src=\"result images/frame_3.jpg\" width=\"400\" height=\"200\"><img src=\"result images/frame_4.jpg\" width=\"400\" height=\"200\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f4739e-adaf-4b1d-b451-a957d47efd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(frame, contours_info):\n",
    "    if contours_info:\n",
    "        contours_info.sort(key=lambda info: info[4] * info[5], reverse=True)\n",
    "        selected_hand, selected_pt, x_contour, y_contour, width, height, selected_contour = contours_info[0]\n",
    "        cv2.rectangle(frame, (x_contour, y_contour), (x_contour + width, y_contour + height), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"{id} {selected_hand} Hand obj\", (x_contour, y_contour - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        return selected_hand, selected_pt, (x_contour, y_contour, width, height)\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e7001a-528e-459e-a486-ab042391d39e",
   "metadata": {},
   "source": [
    "This Python function, handle_tracking, updates the tracker with the current frame and tracks the object specified by the bounding box. It then calculates the coordinates of the tracked bounding box and compares them with the detected keypoints of the hand. If the hand is being tracked successfully, it checks for a throwing action and returns the result along with the updated bounding box. If tracking fails, it returns False along with None for the bounding box.\n",
    "\n",
    "<img src=\"result images/frame_0 (5).jpg\" width=\"400\" height=\"200\"><img src=\"result images/frame_0 (11).jpg\" width=\"400\" height=\"200\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fb67e3b-31eb-451a-89e1-63deec41f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tracking(tracking_frame, frame,tracker, tracker_bbox, keypoints_list, selected_hand):\n",
    "    success, tracker_bbox = tracker.update(tracking_frame)\n",
    "    if success:\n",
    "        p1 = (int(tracker_bbox[0]), int(tracker_bbox[1]))\n",
    "        p2 = (int(tracker_bbox[0] + tracker_bbox[2]), int(tracker_bbox[1] + tracker_bbox[3]))\n",
    "        temp_tracker_box = (int(tracker_bbox[0]), int(tracker_bbox[1]), int(tracker_bbox[2]), int(tracker_bbox[3]))\n",
    "        pt1 = keypoints_list[0][9].astype(int)  # Left hand\n",
    "        pt2 = keypoints_list[0][10].astype(int)\n",
    "        if pt1[0] > pt2[0]:\n",
    "            pt1, pt2 = pt2, pt1\n",
    "        selected_pt_1 = pt1 if selected_hand == \"Left\" else pt2\n",
    "        thrown = is_throwing_action(temp_tracker_box, selected_pt_1)\n",
    "        cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "        cv2.putText(frame, f\"Tracking {current_hand} Hand\", (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        return thrown, tracker_bbox\n",
    "    else:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c90155-a089-471f-82be-b5502a370bfd",
   "metadata": {},
   "source": [
    "This code initializes video capture from a specified file and reads the first frame. It creates a copy of this frame for tracking purposes (tracking_frame). Additionally, it converts the first frame to grayscale (backframe) for background subtraction and further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef69c4d0-2b14-421c-8c79-02cb9b69df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired dimensions (1280x720) not applied. Actual dimensions: 848x480\n"
     ]
    }
   ],
   "source": [
    "video_path = \"videos/WhatsApp Video 2024-05-20 at 10.00.32.mp4\"\n",
    "cap = initialize_video(video_path)\n",
    "ret, backframe = cap.read()\n",
    "tracking_frame = backframe.copy()\n",
    "backframe = cv2.cvtColor(backframe, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15943be8-58df-4f83-b6da-72e885a18f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cap.isOpened():\n",
    "    print(f\"Error: Unable to open video file\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29076645-01f6-449f-a354-9d849c31d6dc",
   "metadata": {},
   "source": [
    "## This code snippet appears to be part of a larger program for real-time object tracking and gesture recognition, likely designed for applications such as computer vision-based interaction or surveillance.\n",
    "\n",
    "- The while loop continuously reads frames from a video capture (cap) until there are no more frames (cap.isOpened()).\n",
    "\n",
    "- It checks if the frame retrieval was successful (ret) and if not, breaks out of the loop, printing an error message.\n",
    "\n",
    "- It initializes a copy of the current frame for object tracking and generates a foreground mask using a function called generate_foreground.\n",
    "\n",
    "- Object detection is performed on the current frame using a function called detect_objects, which likely employs a machine learning model like YOLO (You Only Look Once) to detect objects and their keypoints.\n",
    "\n",
    "- If object tracking has been initialized (tracker_initialized), the program attempts to update the tracker with the current frame. If successful, it calculates the bounding box of the tracked object and performs additional processing to determine the hand's position and whether a throwing action is occurring.\n",
    "\n",
    "- If the tracker fails to update, it indicates that the object might have been lost or occluded, and the tracker is reset for the next iteration.\n",
    "\n",
    "- If object tracking has not been initialized, the program proceeds to perform object detection using YOLO. It extracts bounding boxes and keypoints of detected objects, particularly focusing on hands.\n",
    "\n",
    "- For each detected hand, it creates a mask to isolate the hand region in the foreground mask and finds contours within that region. If contours are found and meet certain criteria, they are considered for tracking.\n",
    "\n",
    "- The largest contour associated with each hand is selected, and its bounding box is drawn on the frame. If a suitable contour is found, object tracking is initialized using that bounding box, and the current hand type is determined for subsequent iterations.\n",
    "\n",
    "- If a throwing action is detected based on the hand's motion, a message is displayed on the frame.\n",
    "\n",
    "- The frame is displayed using OpenCV's imshow function, and the loop continues until the user presses 'q' to quit.\n",
    "\n",
    "- Finally, the video capture is released, and all OpenCV windows are destroyed.\n",
    "\n",
    "This code forms part of a larger system for real-time hand tracking and gesture recognition\n",
    "\n",
    "<img src=\"result images/frame_0 (18).jpg\" width=\"800\" height=\"400\">\n",
    "\n",
    "\n",
    "<img src=\"result images/frame_43.jpg\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60f46616-26a3-43cd-9d8f-1303beec208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 4.2ms preprocess, 70.5ms inference, 1385.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.4ms\n",
      "Speed: 0.9ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[520  64]] : 10.05\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 0.0ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[520  70]] : 4.12\n",
      "\n",
      "0: 384x640 1 person, 13.7ms\n",
      "Speed: 0.0ms preprocess, 13.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[520  73]] : 2.83\n",
      "\n",
      "0: 384x640 1 person, 13.2ms\n",
      "Speed: 0.0ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[520  72]] : 4.47\n",
      "\n",
      "0: 384x640 1 person, 12.6ms\n",
      "Speed: 0.0ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[520  73]] : 5.83\n",
      "\n",
      "0: 384x640 1 person, 12.6ms\n",
      "Speed: 0.0ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[518  73]] : 7.07\n",
      "\n",
      "0: 384x640 1 person, 7.4ms\n",
      "Speed: 10.5ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[518  73]] : 9.06\n",
      "\n",
      "0: 384x640 1 person, 13.7ms\n",
      "Speed: 0.0ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[518  76]] : 7.07\n",
      "\n",
      "0: 384x640 1 person, 20.7ms\n",
      "Speed: 0.0ms preprocess, 20.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2.8ms\n",
      "Speed: 2.0ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[476  75]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[474  78]] : 28.50\n",
      "\n",
      "0: 384x640 1 person, 5.8ms\n",
      "Speed: 11.5ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[473  79]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[473  79]] : 30.50\n",
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 0.0ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[473  80]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 0.0ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[474  81]] : 31.52\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[473  81]] : 32.52\n",
      "\n",
      "0: 384x640 1 person, 17.3ms\n",
      "Speed: 0.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[472  83]] : 32.50\n",
      "\n",
      "0: 384x640 1 person, 2.1ms\n",
      "Speed: 2.0ms preprocess, 2.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[472  86]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 0.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[469  90]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 2.0ms\n",
      "Speed: 2.0ms preprocess, 2.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[470  91]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[470  94]] : 29.52\n",
      "\n",
      "0: 384x640 1 person, 1.3ms\n",
      "Speed: 2.2ms preprocess, 1.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[470  94]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 20.7ms\n",
      "Speed: 0.0ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[468  98]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[469  98]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 1.3ms\n",
      "Speed: 8.7ms preprocess, 1.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[468 100]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[468 105]] : 26.52\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[469 106]] : 27.50\n",
      "\n",
      "0: 384x640 1 person, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[470 106]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[469 109]] : 25.50\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[469 111]] : 24.50\n",
      "\n",
      "0: 384x640 1 person, 3.8ms\n",
      "Speed: 14.2ms preprocess, 3.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[468 112]] : 25.50\n",
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 0.0ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[468 113]] : 26.50\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[467 114]] : 26.52\n",
      "\n",
      "0: 384x640 1 person, 17.3ms\n",
      "Speed: 0.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[467 115]] : 26.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[468 117]] : 27.52\n",
      "\n",
      "0: 384x640 1 person, 16.8ms\n",
      "Speed: 0.0ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[467 119]] : 26.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[467 120]] : 28.50\n",
      "\n",
      "0: 384x640 1 person, 16.8ms\n",
      "Speed: 0.0ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[467 122]] : 27.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[467 123]] : 29.50\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[466 124]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 1.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[466 127]] : 29.50\n",
      "\n",
      "0: 384x640 1 person, 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[465 131]] : 27.52\n",
      "\n",
      "0: 384x640 1 person, 4.7ms\n",
      "Speed: 14.9ms preprocess, 4.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[464 133]] : 28.57\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[463 135]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[463 138]] : 27.57\n",
      "\n",
      "0: 384x640 1 person, 0.3ms\n",
      "Speed: 2.5ms preprocess, 0.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[462 139]] : 28.57\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[462 138]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.9ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[462 140]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[462 142]] : 29.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[462 143]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 17.4ms\n",
      "Speed: 0.0ms preprocess, 17.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[462 144]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[461 148]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 149]] : 28.57\n",
      "\n",
      "0: 384x640 1 person, 1.3ms\n",
      "Speed: 1.0ms preprocess, 1.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 153]] : 27.52\n",
      "\n",
      "0: 384x640 1 person, 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[461 154]] : 27.50\n",
      "\n",
      "0: 384x640 1 person, 19.1ms\n",
      "Speed: 0.0ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 155]] : 29.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[458 158]] : 28.57\n",
      "\n",
      "0: 384x640 1 person, 17.3ms\n",
      "Speed: 0.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 159]] : 29.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 160]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 14.2ms\n",
      "Speed: 0.0ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 161]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[458 165]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[458 169]] : 29.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[458 172]] : 27.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 175]] : 27.50\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 0.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 176]] : 28.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 1.8ms preprocess, 0.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 178]] : 28.50\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 0.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 181]] : 26.52\n",
      "\n",
      "0: 384x640 1 person, 2.1ms\n",
      "Speed: 1.0ms preprocess, 2.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 180]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 9.9ms\n",
      "Speed: 0.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[461 183]] : 28.57\n",
      "\n",
      "0: 384x640 1 person, 3.1ms\n",
      "Speed: 2.0ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 185]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[460 186]] : 29.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 187]] : 30.57\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 190]] : 29.65\n",
      "\n",
      "0: 384x640 1 person, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 191]] : 31.64\n",
      "\n",
      "0: 384x640 1 person, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 194]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 198]] : 29.65\n",
      "\n",
      "0: 384x640 1 person, 0.7ms\n",
      "Speed: 1.9ms preprocess, 0.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 200]] : 30.65\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 201]] : 31.64\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 204]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 10.9ms\n",
      "Speed: 0.0ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 208]] : 31.75\n",
      "\n",
      "0: 384x640 1 person, 19.4ms\n",
      "Speed: 0.0ms preprocess, 19.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 213]] : 29.92\n",
      "\n",
      "0: 384x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 215]] : 29.92\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 0.0ms preprocess, 11.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 218]] : 29.92\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 0.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[453 220]] : 32.07\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 223]] : 30.91\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 2.0ms preprocess, 0.0ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 225]] : 30.76\n",
      "\n",
      "0: 384x640 1 person, 18.6ms\n",
      "Speed: 0.0ms preprocess, 18.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 229]] : 28.66\n",
      "\n",
      "0: 384x640 1 person, 1.4ms\n",
      "Speed: 3.0ms preprocess, 1.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[453 230]] : 29.92\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.7ms preprocess, 0.0ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 230]] : 31.75\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 234]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 234]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 237]] : 31.75\n",
      "\n",
      "0: 384x640 1 person, 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[453 239]] : 30.91\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[452 239]] : 34.03\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 243]] : 31.64\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 0.0ms preprocess, 14.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[458 244]] : 33.50\n",
      "\n",
      "0: 384x640 1 person, 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 247]] : 33.51\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 251]] : 31.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 1.0ms preprocess, 0.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 254]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 259]] : 30.65\n",
      "\n",
      "0: 384x640 1 person, 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 261]] : 31.64\n",
      "\n",
      "0: 384x640 1 person, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 264]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 20.6ms\n",
      "Speed: 0.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 269]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 270]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 274]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 10.8ms\n",
      "Speed: 0.0ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[455 277]] : 27.57\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 279]] : 27.52\n",
      "\n",
      "0: 384x640 1 person, 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 281]] : 27.52\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 282]] : 28.52\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 0.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 284]] : 28.50\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 285]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 287]] : 29.57\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.6ms preprocess, 0.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[459 289]] : 30.57\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[457 293]] : 30.50\n",
      "\n",
      "0: 384x640 1 person, 13.8ms\n",
      "Speed: 0.0ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 296]] : 30.52\n",
      "\n",
      "0: 384x640 1 person, 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 298]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 1.5ms preprocess, 0.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[456 302]] : 31.56\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[453 306]] : 31.89\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.1ms preprocess, 0.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 313]] : 28.78\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[454 317]] : 28.78\n",
      "\n",
      "0: 384x640 1 person, 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[450 322]] : 28.64\n",
      "\n",
      "0: 384x640 1 person, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[452 325]] : 27.95\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 324]] : 32.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 2.3ms preprocess, 0.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 326]] : 33.25\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[451 328]] : 32.88\n",
      "\n",
      "0: 384x640 1 person, 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 332]] : 31.29\n",
      "\n",
      "0: 384x640 1 person, 0.8ms\n",
      "Speed: 2.0ms preprocess, 0.8ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[448 335]] : 31.53\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 0.0ms preprocess, 15.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[448 337]] : 32.50\n",
      "\n",
      "0: 384x640 1 person, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 340]] : 31.29\n",
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 0.0ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 343]] : 31.29\n",
      "\n",
      "0: 384x640 1 person, 10.6ms\n",
      "Speed: 0.9ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[449 344]] : 37.58\n",
      "\n",
      "0: 384x640 1 person, 1.5ms\n",
      "Speed: 2.0ms preprocess, 1.5ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 345]] : 36.59\n",
      "\n",
      "0: 384x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[450 348]] : 36.67\n",
      "\n",
      "0: 384x640 1 person, 4.7ms\n",
      "Speed: 15.6ms preprocess, 4.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[451 352]] : 33.95\n",
      "\n",
      "0: 384x640 1 person, 14.2ms\n",
      "Speed: 0.0ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 355]] : 34.68\n",
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 0.0ms preprocess, 14.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[447 355]] : 37.58\n",
      "\n",
      "0: 384x640 1 person, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[446 360]] : 33.68\n",
      "\n",
      "0: 384x640 1 person, 20.7ms\n",
      "Speed: 0.0ms preprocess, 20.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[443 364]] : 33.59\n",
      "\n",
      "0: 384x640 1 person, 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[439 366]] : 33.50\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 1.2ms preprocess, 0.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[433 368]] : 34.68\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 0.0ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[437 368]] : 35.59\n",
      "\n",
      "0: 384x640 1 person, 10.6ms\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[435 370]] : 36.59\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[435 367]] : 40.75\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 0.0ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[433 373]] : 36.67\n",
      "\n",
      "0: 384x640 1 person, 1.1ms\n",
      "Speed: 2.0ms preprocess, 1.1ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[432 374]] : 36.67\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[432 373]] : 36.91\n",
      "\n",
      "0: 384x640 1 person, 10.1ms\n",
      "Speed: 1.1ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[432 374]] : 38.06\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[432 377]] : 35.11\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 2.3ms preprocess, 0.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[426 380]] : 32.50\n",
      "\n",
      "0: 384x640 1 person, 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[429 378]] : 34.68\n",
      "\n",
      "0: 384x640 1 person, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[432 387]] : 28.50\n",
      "\n",
      "0: 384x640 1 person, 6.6ms\n",
      "Speed: 12.5ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[487 402]] : 65.36\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 10.8ms\n",
      "Speed: 0.0ms preprocess, 10.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[440 403]] : 38.51\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 0.0ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[445 403]] : 41.21\n",
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[444 387]] : 58.15\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[449 388]] : 63.71\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[450 396]] : 58.81\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "left\n",
      "Distance to keypoint  [[458 404]] : 59.22\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 4.2ms\n",
      "Speed: 2.0ms preprocess, 4.2ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "thrown\n",
      "\n",
      "0: 384x640 1 person, 9.8ms\n",
      "Speed: 1.2ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[533 430]] : 9.71\n",
      "\n",
      "0: 384x640 1 person, 5.3ms\n",
      "Speed: 2.2ms preprocess, 5.3ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[531 437]] : 4.72\n",
      "\n",
      "0: 384x640 1 person, 2.4ms\n",
      "Speed: 1.0ms preprocess, 2.4ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2.0ms\n",
      "Speed: 2.0ms preprocess, 2.0ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[525 450]] : 11.01\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[529 465]] : 5.32\n",
      "\n",
      "0: 384x640 1 person, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[520 475]] : 5.59\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[518 479]] : 3.35\n",
      "\n",
      "0: 384x640 1 person, 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Distance to keypoint  [[512 480]] : 3.91\n",
      "\n",
      "0: 384x640 1 person, 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Distance to keypoint  [[482 474]] : 16.77\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 1.2ms preprocess, 0.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.2ms\n",
      "Speed: 0.0ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2.6ms\n",
      "Speed: 2.0ms preprocess, 2.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.2ms\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.7ms\n",
      "Speed: 1.0ms preprocess, 10.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 0.0ms preprocess, 11.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 0.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 1.0ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.1ms\n",
      "Speed: 6.2ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 0.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.7ms\n",
      "Speed: 3.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 0.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 1.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.7ms\n",
      "Speed: 1.0ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 1.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 3.0ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 0.5ms\n",
      "Speed: 1.7ms preprocess, 0.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 0.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 0.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Error: Unable to read frame\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read frame\")\n",
    "        break\n",
    "    tracking_frame = frame.copy()\n",
    "    fgMask=generate_foreground(frame)\n",
    "    boundingboxes, keypoints_list, ids = detect_objects(frame)\n",
    "    # if results[0].boxes.id is not None:\n",
    "    #     ids = results[0].boxes.id.cpu().numpy()  # Extract track IDs\n",
    "\n",
    "    if tracker_initialized:\n",
    "        # thrown, tracker_bbox = handle_tracking(tracking_frame,frame, tracker, tracker_bbox, keypoints_list, current_hand)\n",
    "        success, tracker_bbox = tracker.update(tracking_frame)\n",
    "        if success:\n",
    "\n",
    "            p1 = (int(tracker_bbox[0]), int(tracker_bbox[1]))\n",
    "            p2 = (int(tracker_bbox[0] + tracker_bbox[2]), int(tracker_bbox[1] + tracker_bbox[3]))\n",
    "            # print_distances_to_keypoints(tracker_bbox, keypoints_list[0])\n",
    "            temp_tracker_box=(int(tracker_bbox[0]), int(tracker_bbox[1]),int(tracker_bbox[2]),int(tracker_bbox[3]))\n",
    "            # print(temp_tracker_box)\n",
    "            pt1 = keypoints_list[0][9].astype(int)  # Left hand\n",
    "            pt2 = keypoints_list[0][10].astype(int)\n",
    "            if pt1[0] > pt2[0]:\n",
    "                pt1, pt2 = pt2, pt1\n",
    "            if selected_hand==\"Left\":\n",
    "                print(\"left\")\n",
    "                selected_pt_1=pt1\n",
    "            else:\n",
    "                print(\"Right\")\n",
    "                selected_pt_1=pt2\n",
    "            # print(keypoints_list)\n",
    "            # print(tracker_bbox)\n",
    "            # print(selected_pt_1)\n",
    "            obj_center = (int(tracker_bbox[0]) + int(tracker_bbox[2]) // 2, int(tracker_bbox[1]) + int(tracker_bbox[3]) // 2)\n",
    "            # print(obj_center)\n",
    "            thrown=is_throwing_action(temp_tracker_box,selected_pt_1)\n",
    "            # print(obj_center)\n",
    "            # print(keypoints_list)\n",
    "            # print(selected_pt)\n",
    "            # cv2.line(frame,obj_center,selected_pt_1,(255, 0, 0), 2)\n",
    "            cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "            cv2.putText(frame, f\"Tracking {current_hand} Hand\", (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        else:\n",
    "            tracker_initialized = False  # Tracker failed, reinitialize in the next iteration\n",
    "    else:\n",
    "        # Object tracking with YOLO\n",
    "        if len(ids) > 0:\n",
    "            for bbox, keypoints, id in zip(boundingboxes, keypoints_list, ids):\n",
    "                x, y, w, h = bbox.astype(int)\n",
    "                pt1 = keypoints[9].astype(int)  # Left hand\n",
    "                pt2 = keypoints[10].astype(int)  # Right hand\n",
    "                if not (0 <= pt1[0] < frame.shape[1] and 0 <= pt1[1] < frame.shape[0]):\n",
    "                    continue\n",
    "                if not (0 <= pt2[0] < frame.shape[1] and 0 <= pt2[1] < frame.shape[0]):\n",
    "                    continue\n",
    "\n",
    "                height_hand = h // 2\n",
    "                width_hand = w\n",
    "                if pt1[0] > pt2[0]:\n",
    "                    pt1, pt2 = pt2, pt1\n",
    "\n",
    "                x_l_hand = max(pt1[0] + (width_hand // 5), 0)\n",
    "                y_l_hand = max(pt1[1], 0)\n",
    "                x_l_hand_end = max(pt1[0] - width_hand, 0)\n",
    "                y_l_hand_end = max(pt1[1] + height_hand, 0)\n",
    "\n",
    "                x_r_hand = max(pt2[0] - (width_hand // 5), 0)\n",
    "                y_r_hand = max(pt2[1], 0)\n",
    "                x_r_hand_end = min(pt2[0] + width_hand, frame.shape[1])\n",
    "                y_r_hand_end = min(pt2[1] + height_hand, frame.shape[0])\n",
    "\n",
    "                contours_info = []\n",
    "\n",
    "                if (0 <= x_l_hand < frame.shape[1] and 0 <= y_l_hand < frame.shape[0] and\n",
    "                        0 <= x_l_hand_end <= frame.shape[1] and 0 <= y_l_hand_end <= frame.shape[0]):\n",
    "\n",
    "                    mask_l_hand = np.zeros(fgMask.shape[:2], dtype=\"uint8\")\n",
    "                    cv2.rectangle(mask_l_hand, (x_l_hand, y_l_hand), (x_l_hand_end, y_l_hand_end), 255, -1)\n",
    "                    fgMask_l_hand = cv2.bitwise_and(fgMask, fgMask, mask=mask_l_hand)\n",
    "                    contours_l_hand, hierarchy_l_hand = cv2.findContours(fgMask_l_hand, cv2.RETR_EXTERNAL,\n",
    "                                                                         cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "                    if len(contours_l_hand) > 0:\n",
    "                        largest_contour_l = max(contours_l_hand, key=cv2.contourArea)\n",
    "                        if is_contour_connected_to_keypoint(largest_contour_l, pt1):\n",
    "                            x_contour, y_contour, width, height = cv2.boundingRect(largest_contour_l)\n",
    "                            contours_info.append((\"Left\", pt1, x_contour, y_contour, width, height, largest_contour_l))\n",
    "\n",
    "                if (0 <= x_r_hand < frame.shape[1] and 0 <= y_r_hand < frame.shape[0] and\n",
    "                        0 <= x_r_hand_end <= frame.shape[1] and 0 <= y_r_hand_end <= frame.shape[0]):\n",
    "\n",
    "                    mask_r_hand = np.zeros(fgMask.shape[:2], dtype=\"uint8\")\n",
    "                    cv2.rectangle(mask_r_hand, (x_r_hand, y_r_hand), (x_r_hand_end, y_r_hand_end), 255, -1)\n",
    "                    fgMask_r_hand = cv2.bitwise_and(fgMask, fgMask, mask=mask_r_hand)\n",
    "                    contours_r_hand, hierarchy_r_hand = cv2.findContours(fgMask_r_hand, cv2.RETR_EXTERNAL,\n",
    "                                                                         cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "                    if len(contours_r_hand) > 0:\n",
    "                        largest_contour_r = max(contours_r_hand, key=cv2.contourArea)\n",
    "                        if is_contour_connected_to_keypoint(largest_contour_r, pt2):\n",
    "                            x_contour, y_contour, width, height = cv2.boundingRect(largest_contour_r)\n",
    "                            contours_info.append((\"Right\", pt2, x_contour, y_contour, width, height, largest_contour_r))\n",
    "\n",
    "                selected_hand, selected_pt, tracker_bbox = draw_contours(frame, contours_info)\n",
    "                if tracker_bbox:\n",
    "                        tracker = cv2.TrackerKCF_create()\n",
    "                        tracker.init(tracking_frame, tracker_bbox)\n",
    "                        tracker_initialized = True\n",
    "                        current_hand = selected_hand\n",
    "                        thrown = is_throwing_action(tracker_bbox, selected_pt)\n",
    "\n",
    "    if thrown:\n",
    "        print(\"thrown\")\n",
    "        cv2.putText(frame, f\"Throwing action detected\", (100, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    # frame=results[0].plot()\n",
    "    cv2.imshow('Frame', frame)\n",
    "    # cv2.imshow('Frame_2', fgMask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
